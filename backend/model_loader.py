import joblib
import os
import sys
import gc

def load_ai_models(models_dir="models"):
    """
    Charge les 3 fichiers n√©cessaires au mod√®le (Mod√®le, Scaler, Encoder).
    G√®re les chemins relatifs pour Docker.
    Optimisation M√©moire : Garbage Collection imm√©diat.
    """
    print(f"üîÑ Chargement des mod√®les depuis : {models_dir}...")
    
    try:
        model_path = os.path.join(models_dir, "type_beat_model.pkl")
        scaler_path = os.path.join(models_dir, "scaler.pkl")
        encoder_path = os.path.join(models_dir, "encoder.pkl")

        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Fichier mod√®le introuvable: {model_path}")

        # Chargement avec joblib
        model = joblib.load(model_path)
        scaler = joblib.load(scaler_path)
        encoder = joblib.load(encoder_path)

        # R√©cup√©ration des features attendues (si disponible dans le scaler)
        expected_features = getattr(scaler, 'feature_names_in_', None)

        # Lib√©ration imm√©diate de la m√©moire temporaire
        gc.collect()

        print("‚úÖ Mod√®les charg√©s avec succ√®s.")
        return model, scaler, encoder, expected_features

    except Exception as e:
        print(f"‚ùå Erreur critique lors du chargement du mod√®le : {e}")
        # En production, on veut peut-√™tre stopper le conteneur si le mod√®le ne charge pas
        sys.exit(1) 
